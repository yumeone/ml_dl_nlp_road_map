{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Amazon SageMaker is a fully managed machine learning service. \n",
    "\n",
    "* easily build and train machine learning models, and then directly deploy them into a production-ready hosted environment. \n",
    "\n",
    "* It provides an integrated Jupyter authoring notebook instance for easy access to your data sources for exploration and analysis, so you don't have to manage servers\n",
    "\n",
    "* . It also provides common machine learning algorithms that are optimized to run efficiently against extremely large data in a distributed environment.\n",
    "\n",
    "\n",
    "![img.png](https://docs.aws.amazon.com/sagemaker/latest/dg/images/ml-concepts-10.png)\n",
    "\n",
    "### What is Boto\n",
    "\n",
    "Boto is the Amazon Web Services (AWS) SDK for Python. It enables Python developers to create, configure, and manage AWS services, such as EC2 and S3. Boto provides an easy to use, object-oriented API, as well as low-level access to AWS services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import successfull\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "from sagemaker.session import s3_input, Session\n",
    "print('import successfull')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-east-1\n"
     ]
    }
   ],
   "source": [
    " # <--- CHANGE THIS VARIABLE TO A UNIQUE NAME FOR YOUR BUCKET\n",
    "BUCKET_NAME = 'bank-churn-app2020'\n",
    "## set the region of the instance\n",
    "my_region = boto3.session.Session().region_name\n",
    "print(my_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3.ServiceResource()\n"
     ]
    }
   ],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "print(s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bucket created successfully\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    if my_region=='us-east-1':\n",
    "        s3.create_bucket(Bucket =BUCKET_NAME)\n",
    "        print('bucket created successfully')\n",
    "except Exception as e:\n",
    "    print(f's3 error{e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://bank-churn-app2020/xgboost-inbulit-algo\n"
     ]
    }
   ],
   "source": [
    "# set an output path where the trained model will be saved\n",
    "prefix = 'xgboost-inbulit-algo'\n",
    "OUTPUT_PATH = f's3://{BUCKET_NAME}/{prefix}'\n",
    "print(OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloading the dataset and storing into S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: downloaded bank_clean.csv.\n",
      "Success: Data loaded into dataframe.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    urllib.request.urlretrieve (\"https://d1.awsstatic.com/tmt/build-train-deploy-machine-learning-model-sagemaker/bank_clean.27f01fbbdf43271788427f3682996ae29ceca05d.csv\", \"bank_clean.csv\")\n",
    "    print('Success: downloaded bank_clean.csv.')\n",
    "except Exception as e:\n",
    "    print('Data load error: ',e)\n",
    "\n",
    "try:\n",
    "    model_data = pd.read_csv('./bank_clean.csv',index_col=0)\n",
    "    print('Success: Data loaded into dataframe.')\n",
    "except Exception as e:\n",
    "    print('Data load error: ',e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bank-churn-app2020.ipynb  bank_clean.csv  lost+found  test.csv\ttrain.csv\r\n"
     ]
    }
   ],
   "source": [
    "! dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28831, 61) (12357, 61)\n"
     ]
    }
   ],
   "source": [
    "# Train_test split\n",
    "train_data , test_data = np.split(model_data.sample(frac=1,random_state=42),[int(0.7*len(model_data))])\n",
    "print(train_data.shape , test_data.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "### Saving Train And Test Into Buckets\n",
    "## We start with Train Data\n",
    "import os\n",
    "# creating train dataset for model\n",
    "pd.concat([train_data['y_yes'], train_data.drop(['y_no', 'y_yes'], \n",
    "                                                axis=1)], \n",
    "                                                axis=1).to_csv('train.csv', index=False, header=False)\n",
    "\n",
    "# uploding the train dataset to s3 bucket \n",
    "boto3.Session().resource('s3').Bucket(BUCKET_NAME).Object(os.path.join(prefix, 'train/train.csv')).upload_file('train.csv')\n",
    "\n",
    "s3_input_train = sagemaker.s3_input(s3_data=f's3://{BUCKET_NAME}/{prefix}/train', content_type='csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "# Test Data Into Buckets\n",
    "pd.concat([test_data['y_yes'], test_data.drop(['y_no', 'y_yes'], axis=1)], axis=1).to_csv('test.csv', index=False, header=False)\n",
    "\n",
    "boto3.Session().resource('s3').Bucket(BUCKET_NAME).Object(os.path.join(prefix, 'test/test.csv')).upload_file('test.csv')\n",
    "\n",
    "s3_input_test = sagemaker.s3_input(s3_data=f's3://{BUCKET_NAME}/{prefix}/test', content_type='csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building model: inbuilt model xgboost\n",
    "\n",
    "* Fetch the container with the corresponding algorithm to use from the list of pre-defined Sagemaker algorithms or give your own custom container to support custom algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'get_image_uri' method will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "# this line automatically looks for the XGBoost image URI and builds an XGBoost container.\n",
    "# specify the repo_version depending on your preference.\n",
    "container = get_image_uri(boto3.Session().region_name,\n",
    "                          'xgboost', \n",
    "                          repo_version='1.0-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:1.0-1-cpu-py3'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize hyperparameters\n",
    "hyperparameters = {\n",
    "        \"max_depth\":\"5\",\n",
    "        \"eta\":\"0.2\",\n",
    "        \"gamma\":\"4\",\n",
    "        \"min_child_weight\":\"6\",\n",
    "        \"subsample\":\"0.7\",\n",
    "        \"objective\":\"binary:logistic\",\n",
    "        \"num_round\":50\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': '5',\n",
       " 'eta': '0.2',\n",
       " 'gamma': '4',\n",
       " 'min_child_weight': '6',\n",
       " 'subsample': '0.7',\n",
       " 'objective': 'binary:logistic',\n",
       " 'num_round': 50}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sagemaker.estimator.Estimator at 0x7f880edfe160>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct a SageMaker estimator that calls the xgboost-container\n",
    "estimator = sagemaker.estimator.Estimator(image_name=container, \n",
    "                                          hyperparameters=hyperparameters,\n",
    "                                          role=sagemaker.get_execution_role(),\n",
    "                                          train_instance_count=1, \n",
    "                                          train_instance_type='ml.m5.2xlarge', \n",
    "                                          train_volume_size=5, # 5 GB \n",
    "                                          output_path=OUTPUT_PATH,\n",
    "                                          train_use_spot_instances=True,\n",
    "                                          train_max_run=300,\n",
    "                                          train_max_wait=600)\n",
    "estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-02 06:15:47 Starting - Starting the training job...\n",
      "2020-09-02 06:15:50 Starting - Launching requested ML instances......\n",
      "2020-09-02 06:17:04 Starting - Preparing the instances for training......\n",
      "2020-09-02 06:18:17 Downloading - Downloading input data\n",
      "2020-09-02 06:18:17 Training - Downloading the training image...\n",
      "2020-09-02 06:18:44 Uploading - Uploading generated training model\n",
      "2020-09-02 06:18:44 Completed - Training job completed\n",
      "\u001b[34mINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_xgboost_container.training:Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[06:18:34] 28831x59 matrix with 1701029 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[06:18:34] 12357x59 matrix with 729063 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34mINFO:root:Single node training.\u001b[0m\n",
      "\u001b[34mINFO:root:Train matrix has 28831 rows\u001b[0m\n",
      "\u001b[34mINFO:root:Validation matrix has 12357 rows\u001b[0m\n",
      "\u001b[34m[06:18:34] WARNING: /workspace/src/learner.cc:328: \u001b[0m\n",
      "\u001b[34mParameters: { num_round } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m[0]#011train-error:0.10170#011validation-error:0.10512\u001b[0m\n",
      "\u001b[34m[1]#011train-error:0.10093#011validation-error:0.10375\u001b[0m\n",
      "\u001b[34m[2]#011train-error:0.10014#011validation-error:0.10269\u001b[0m\n",
      "\u001b[34m[3]#011train-error:0.09972#011validation-error:0.10286\u001b[0m\n",
      "\u001b[34m[4]#011train-error:0.10010#011validation-error:0.10237\u001b[0m\n",
      "\u001b[34m[5]#011train-error:0.10055#011validation-error:0.10108\u001b[0m\n",
      "\u001b[34m[6]#011train-error:0.10052#011validation-error:0.10091\u001b[0m\n",
      "\u001b[34m[7]#011train-error:0.10038#011validation-error:0.10148\u001b[0m\n",
      "\u001b[34m[8]#011train-error:0.10010#011validation-error:0.10124\u001b[0m\n",
      "\u001b[34m[9]#011train-error:0.10017#011validation-error:0.10132\u001b[0m\n",
      "\u001b[34m[10]#011train-error:0.10048#011validation-error:0.10156\u001b[0m\n",
      "\u001b[34m[11]#011train-error:0.10000#011validation-error:0.10156\u001b[0m\n",
      "\u001b[34m[12]#011train-error:0.10010#011validation-error:0.10189\u001b[0m\n",
      "\u001b[34m[13]#011train-error:0.10055#011validation-error:0.10205\u001b[0m\n",
      "\u001b[34m[14]#011train-error:0.10034#011validation-error:0.10189\u001b[0m\n",
      "\u001b[34m[15]#011train-error:0.09996#011validation-error:0.10205\u001b[0m\n",
      "\u001b[34m[16]#011train-error:0.09986#011validation-error:0.10229\u001b[0m\n",
      "\u001b[34m[17]#011train-error:0.09968#011validation-error:0.10245\u001b[0m\n",
      "\u001b[34m[18]#011train-error:0.09965#011validation-error:0.10229\u001b[0m\n",
      "\u001b[34m[19]#011train-error:0.09920#011validation-error:0.10221\u001b[0m\n",
      "\u001b[34m[20]#011train-error:0.09899#011validation-error:0.10189\u001b[0m\n",
      "\u001b[34m[21]#011train-error:0.09899#011validation-error:0.10189\u001b[0m\n",
      "\u001b[34m[22]#011train-error:0.09913#011validation-error:0.10181\u001b[0m\n",
      "\u001b[34m[23]#011train-error:0.09896#011validation-error:0.10213\u001b[0m\n",
      "\u001b[34m[24]#011train-error:0.09882#011validation-error:0.10269\u001b[0m\n",
      "\u001b[34m[25]#011train-error:0.09889#011validation-error:0.10221\u001b[0m\n",
      "\u001b[34m[26]#011train-error:0.09871#011validation-error:0.10261\u001b[0m\n",
      "\u001b[34m[27]#011train-error:0.09868#011validation-error:0.10245\u001b[0m\n",
      "\u001b[34m[28]#011train-error:0.09899#011validation-error:0.10302\u001b[0m\n",
      "\u001b[34m[29]#011train-error:0.09868#011validation-error:0.10261\u001b[0m\n",
      "\u001b[34m[30]#011train-error:0.09847#011validation-error:0.10229\u001b[0m\n",
      "\u001b[34m[31]#011train-error:0.09833#011validation-error:0.10197\u001b[0m\n",
      "\u001b[34m[32]#011train-error:0.09830#011validation-error:0.10189\u001b[0m\n",
      "\u001b[34m[33]#011train-error:0.09809#011validation-error:0.10197\u001b[0m\n",
      "\u001b[34m[34]#011train-error:0.09819#011validation-error:0.10148\u001b[0m\n",
      "\u001b[34m[35]#011train-error:0.09830#011validation-error:0.10164\u001b[0m\n",
      "\u001b[34m[36]#011train-error:0.09837#011validation-error:0.10172\u001b[0m\n",
      "\u001b[34m[37]#011train-error:0.09844#011validation-error:0.10189\u001b[0m\n",
      "\u001b[34m[38]#011train-error:0.09847#011validation-error:0.10197\u001b[0m\n",
      "\u001b[34m[39]#011train-error:0.09882#011validation-error:0.10148\u001b[0m\n",
      "\u001b[34m[40]#011train-error:0.09844#011validation-error:0.10156\u001b[0m\n",
      "\u001b[34m[41]#011train-error:0.09830#011validation-error:0.10164\u001b[0m\n",
      "\u001b[34m[42]#011train-error:0.09816#011validation-error:0.10156\u001b[0m\n",
      "\u001b[34m[43]#011train-error:0.09809#011validation-error:0.10164\u001b[0m\n",
      "\u001b[34m[44]#011train-error:0.09812#011validation-error:0.10132\u001b[0m\n",
      "\u001b[34m[45]#011train-error:0.09805#011validation-error:0.10164\u001b[0m\n",
      "\u001b[34m[46]#011train-error:0.09785#011validation-error:0.10197\u001b[0m\n",
      "\u001b[34m[47]#011train-error:0.09778#011validation-error:0.10172\u001b[0m\n",
      "\u001b[34m[48]#011train-error:0.09795#011validation-error:0.10124\u001b[0m\n",
      "\u001b[34m[49]#011train-error:0.09778#011validation-error:0.10156\u001b[0m\n",
      "Training seconds: 54\n",
      "Billable seconds: 25\n",
      "Managed Spot Training savings: 53.7%\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({'train': s3_input_train,'validation': s3_input_test})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deploy ml model as endpoint\n",
    "\n",
    "* Deploy the Trained Model using the Sagemaker API. Provide the instance type and instance count as required. Once the deployment is complete, the test data is used to test the deployed application.\n",
    "\n",
    "* Once the Model is deployed an http endpoint is generated which is used by other applications such as a lambda function which is part of a streaming application or a synchronous application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sagemaker.predictor.RealTimePredictor at 0x7f880e9f4d68>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_predictor = estimator.deploy(initial_instance_count=1,instance_type='ml.m4.xlarge')\n",
    "xgb_predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prediction for test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12357,)\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.predictor import csv_serializer\n",
    "test_data_array = test_data.drop(['y_no', 'y_yes'], axis=1).values #load the data into an array\n",
    "xgb_predictor.content_type = 'text/csv' # set the data type for an inference\n",
    "xgb_predictor.serializer = csv_serializer # set the serializer type\n",
    "predictions = xgb_predictor.predict(test_data_array).decode('utf-8') # predict!\n",
    "predictions_array = np.fromstring(predictions[1:], sep=',') # and turn the prediction into an array\n",
    "print(predictions_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02587362, 0.02734977, 0.08641617, ..., 0.68751293, 0.04483907,\n",
       "       0.10314494])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Classification Rate: 89.8%\n",
      "\n",
      "Predicted      No Purchase    Purchase\n",
      "Observed\n",
      "No Purchase    91% (10809)    34% (152)\n",
      "Purchase        9% (1103)     66% (293) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm = pd.crosstab(index=test_data['y_yes'], columns=np.round(predictions_array), rownames=['Observed'], colnames=['Predicted'])\n",
    "tn = cm.iloc[0,0]; fn = cm.iloc[1,0]; tp = cm.iloc[1,1]; fp = cm.iloc[0,1]; p = (tp+tn)/(tp+tn+fp+fn)*100\n",
    "print(\"\\n{0:<20}{1:<4.1f}%\\n\".format(\"Overall Classification Rate: \", p))\n",
    "print(\"{0:<15}{1:<15}{2:>8}\".format(\"Predicted\", \"No Purchase\", \"Purchase\"))\n",
    "print(\"Observed\")\n",
    "print(\"{0:<15}{1:<2.0f}% ({2:<}){3:>6.0f}% ({4:<})\".format(\"No Purchase\", tn/(tn+fn)*100,tn, fp/(tp+fp)*100, fp))\n",
    "print(\"{0:<16}{1:<1.0f}% ({2:<}){3:>7.0f}% ({4:<}) \\n\".format(\"Purchase\", fn/(tn+fn)*100,fn, tp/(tp+fp)*100, tp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deleting Endpoints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker.Session().delete_endpoint(xgb_predictor.endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ResponseMetadata': {'RequestId': 'FN7W4G9SFN2TET0Y',\n",
       "   'HostId': 'WaJo6SkGgrq9DnaYhVABM2F3S12L7L22RP8CH/qIcQ0Twjdud2eUlKGDt6b6mwHnuxpO1B5TXXA=',\n",
       "   'HTTPStatusCode': 200,\n",
       "   'HTTPHeaders': {'x-amz-id-2': 'WaJo6SkGgrq9DnaYhVABM2F3S12L7L22RP8CH/qIcQ0Twjdud2eUlKGDt6b6mwHnuxpO1B5TXXA=',\n",
       "    'x-amz-request-id': 'FN7W4G9SFN2TET0Y',\n",
       "    'date': 'Wed, 02 Sep 2020 06:26:33 GMT',\n",
       "    'connection': 'close',\n",
       "    'content-type': 'application/xml',\n",
       "    'transfer-encoding': 'chunked',\n",
       "    'server': 'AmazonS3'},\n",
       "   'RetryAttempts': 0},\n",
       "  'Deleted': [{'Key': 'xgboost-inbulit-algo/test/test.csv'},\n",
       "   {'Key': 'xgboost-inbulit-algo/train/train.csv'},\n",
       "   {'Key': 'xgboost-inbulit-algo/sagemaker-xgboost-2020-09-02-06-15-45-867/output/model.tar.gz'}]}]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket_to_delete = boto3.resource('s3').Bucket(BUCKET_NAME)\n",
    "bucket_to_delete.objects.all().delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
